{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differentiable argmax / Soft argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\.conda\\envs\\datascience\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Input, Dense, Conv1D, Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DifferentiableArgmax(Layer):\n",
    "    '''\n",
    "    Differentiable argmax / Soft argmax\n",
    "    \n",
    "    Numerically stable in classical neural network value range (-3..3)\n",
    "    Likely to work between -6..6 but not fully tested\n",
    "    \n",
    "    For using with convolutional filters you might want to swap axes:\n",
    "    \n",
    "    c = Conv1D(4, 3) (input)\n",
    "    argmax = DifferentiableArgmax() (c)\n",
    "    argmax -> maximum of filters per width step (Which filter fire stronger at width steps?)\n",
    "    \n",
    "    vs\n",
    "    \n",
    "    c = Conv1D(4, 3) (input)\n",
    "    argmax = tf.transpose(c, perm=[0,2,1]) # (batch, width, filter) -> (batch, filter, width)\n",
    "    argmax = DifferentiableArgmax() (argmax)\n",
    "    argmax -> maximum in width dimension per filter (Where the filters fire strongest?)\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, inputs):       \n",
    "        # For numerical stability -> sum never zero\n",
    "        scaling = tf.math.exp(inputs)\n",
    "        \n",
    "        # Make small values smaller, high values higher -> easier to find difference between 0.1 and 0.11\n",
    "        a = tf.math.pow(scaling, 10) \n",
    "        sum_a = tf.reduce_sum(a, axis=-1)\n",
    "        sum_a = tf.expand_dims(sum_a, axis=-1)\n",
    "        # Ideally highest value 1, everything else is zero\n",
    "        onehot = tf.divide(a, sum_a)\n",
    "        \n",
    "        # Variable onehot might be a ambiguous if input values are close to each other\n",
    "        # Solution: repeat cycle one or more times\n",
    "        a = tf.math.pow(onehot, 10) \n",
    "        sum_a = tf.reduce_sum(a, axis=-1)\n",
    "        sum_a = tf.expand_dims(sum_a, axis=-1)\n",
    "        onehot = tf.divide(a, sum_a)\n",
    "        \n",
    "        a = tf.math.pow(onehot, 10) \n",
    "        sum_a = tf.reduce_sum(a, axis=-1)\n",
    "        sum_a = tf.expand_dims(sum_a, axis=-1)\n",
    "        onehot = tf.divide(a, sum_a)\n",
    "        \n",
    "        a = tf.math.pow(onehot, 10) \n",
    "        sum_a = tf.reduce_sum(a, axis=-1)\n",
    "        sum_a = tf.expand_dims(sum_a, axis=-1)\n",
    "        onehot = tf.divide(a, sum_a)\n",
    "        \n",
    "        # Get argmax of one-hot encoded input\n",
    "        cumsum = tf.cumsum(onehot, axis = -1, exclusive = True, reverse = True)\n",
    "        rounding = 2*(tf.clip_by_value(cumsum, clip_value_min=.5, clip_value_max=1) - .5)\n",
    "        token = tf.reduce_sum(rounding, axis = -1)\n",
    "        token = tf.expand_dims(token, axis=-1)\n",
    "        \n",
    "        return [inputs, token]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model (for random values test)\n",
    "input0 =  Input((1))\n",
    "d = Dense(5, use_bias=False, name='output') (input0)\n",
    "argmax = DifferentiableArgmax()(d)\n",
    "model = Model(input0, [argmax])\n",
    "model.compile(optimizer='adam', loss='mae')\n",
    "#model.summary()\n",
    "\n",
    "# Random value test\n",
    "prediction = model.predict([-2, -1, 0, 1, 2])\n",
    "print('Input of argmax (5 sample. 1 list of 5 random values per sample):\\n', prediction[0])\n",
    "print('\\nOutput of argmax (index of maximum in lists):\\n', prediction[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Get indexes where convolutional filters fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 7\n",
    "channels= 1\n",
    "\n",
    "# Model\n",
    "input0 =  Input((timesteps, channels))\n",
    "c = Conv1D(4, 3, padding='valid') (input0)\n",
    "argmax = tf.transpose(c, perm=[0,2,1]) # (batch, width, filter) -> (batch, filter, width)\n",
    "argmax = DifferentiableArgmax() (argmax)\n",
    "model = Model(input0, argmax)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "#model.summary()\n",
    "\n",
    "# Print values\n",
    "samples = [[np.random.random_sample((timesteps,channels))] * 2]\n",
    "prediction = model.predict(samples)\n",
    "print('Input of argmax:\\n', prediction[0])\n",
    "print('\\nOutput of argmax:\\n', prediction[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shape test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([1.0, 4.0, 1.0, 1.0])\n",
    "print('x')\n",
    "print(x)\n",
    "print()\n",
    "\n",
    "argmax = DifferentiableArgmax() (x)\n",
    "print('argmax')\n",
    "print(argmax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([[1.0, 4.0, 1.0, 1.0], [1.0, 1.0, 1.0, 2.0]])\n",
    "print('x')\n",
    "print(x)\n",
    "print()\n",
    "\n",
    "argmax = DifferentiableArgmax() (x)\n",
    "print('argmax')\n",
    "print(argmax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([[[1.0, 4.0, 1.0, 1.0], [1.0, 4.0, 1.0, 1.0]],\n",
    "                 [[1.0, 4.0, 1.0, 1.0], [1.0, 1.0, 1.0, 2.0]]])\n",
    "print('x')\n",
    "print(x)\n",
    "print()\n",
    "\n",
    "argmax = DifferentiableArgmax() (x)\n",
    "print('argmax')\n",
    "print(argmax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([0., 0., 0., 0.])\n",
    "print('x')\n",
    "print(x)\n",
    "print()\n",
    "\n",
    "argmax = DifferentiableArgmax() (x)\n",
    "print('argmax')\n",
    "print(argmax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = tf.constant([0., 0.0001, 0, 0.])\n",
    "x1 = tf.constant([0., 0.001, 0, 0.])\n",
    "x2 = tf.constant([0., 0.01, 0, 0.])\n",
    "x3 = tf.constant([0., 0.1, 0, 0.])\n",
    "print('x')\n",
    "print(x0)\n",
    "print(x1)\n",
    "print(x2)\n",
    "print(x3)\n",
    "print()\n",
    "\n",
    "argmax0 = DifferentiableArgmax() (x0)\n",
    "argmax1 = DifferentiableArgmax() (x1)\n",
    "argmax2 = DifferentiableArgmax() (x2)\n",
    "argmax3 = DifferentiableArgmax() (x3)\n",
    "print('argmax')\n",
    "print(argmax0[1])\n",
    "print(argmax1[1])\n",
    "print(argmax2[1])\n",
    "print(argmax3[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extreme value test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minus end of stability\n",
    "x = tf.constant([-11., -11., -10., -11.])\n",
    "print('x')\n",
    "print(x)\n",
    "print()\n",
    "\n",
    "argmax = DifferentiableArgmax() (x)\n",
    "print('argmax')\n",
    "print(argmax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minus begining of instability\n",
    "x = tf.constant([-11., -12., -12., -12.])\n",
    "print('x')\n",
    "print(x)\n",
    "print()\n",
    "\n",
    "argmax = DifferentiableArgmax() (x)\n",
    "print('argmax')\n",
    "print(argmax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plus end of stability\n",
    "x = tf.constant([7., 7., 7., 8.])\n",
    "print('x')\n",
    "print(x)\n",
    "print()\n",
    "\n",
    "argmax = DifferentiableArgmax() (x)\n",
    "print('argmax')\n",
    "print(argmax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plus begining of instability\n",
    "x = tf.constant([8., 8., 8., 9.])\n",
    "print('x')\n",
    "print(x)\n",
    "print()\n",
    "\n",
    "argmax = DifferentiableArgmax() (x)\n",
    "print('argmax')\n",
    "print(argmax[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning tensorflow data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [2 3]\n",
      " [4 5]\n",
      " [6 7]\n",
      " [8 9]]\n",
      "[-1 -2 -3 -4 -5]\n"
     ]
    }
   ],
   "source": [
    "# Create dummy data\n",
    "array_a = np.array([[0, 1], [2, 3], [4, 5], [6, 7], [8, 9]])\n",
    "array_b = np.array([-1, -2, -3, -4, -5])\n",
    "print(array_a)\n",
    "print(array_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]  ,  -1\n",
      "[2 3]  ,  -2\n",
      "[4 5]  ,  -3\n",
      "[6 7]  ,  -4\n",
      "[8 9]  ,  -5\n"
     ]
    }
   ],
   "source": [
    "# Define tensorflow dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((array_a, array_b))\n",
    "for a,b in dataset:\n",
    "    print(a.numpy(), ' , ', b.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.        0.6931472]  ,  -1\n",
      "[1.0986123 1.3862944]  ,  -2\n",
      "[1.609438  1.7917595]  ,  -3\n",
      "[1.9459101 2.0794415]  ,  -4\n",
      "[2.1972246 2.3025851]  ,  -5\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing: Apply Python functions\n",
    "def tf_some_python_function(input_a, input_b):\n",
    "    [input_a,] = tf.py_function(np.log1p, [input_a], [tf.float32])\n",
    "    return input_a, input_b\n",
    "\n",
    "mapped_dataset = dataset.map(tf_some_python_function)\n",
    "\n",
    "for a,b in mapped_dataset:\n",
    "    print(a.numpy(), ' , ', b.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batched data, keep partial:\n",
      "batch 0\n",
      "[[0 1]\n",
      " [2 3]]\n",
      "[-1 -2]\n",
      "batch 1\n",
      "[[4 5]\n",
      " [6 7]]\n",
      "[-3 -4]\n",
      "batch 2\n",
      "[[8 9]]\n",
      "[-5]\n",
      "\n",
      "Batched data, keep partial, repeat:\n",
      "batch 0\n",
      "[[0 1]\n",
      " [2 3]]\n",
      "[-1 -2]\n",
      "batch 1\n",
      "[[4 5]\n",
      " [6 7]]\n",
      "[-3 -4]\n",
      "batch 2\n",
      "[[8 9]]\n",
      "[-5]\n",
      "batch 3\n",
      "[[0 1]\n",
      " [2 3]]\n",
      "[-1 -2]\n",
      "batch 4\n",
      "[[4 5]\n",
      " [6 7]]\n",
      "[-3 -4]\n"
     ]
    }
   ],
   "source": [
    "# Batches\n",
    "batch_size = 2\n",
    "take_n_batch = 5\n",
    "\n",
    "print('\\nBatched data, keep partial:')            \n",
    "batched_dataset = dataset.batch(batch_size, drop_remainder=False)\n",
    "\n",
    "for i, batch in enumerate(batched_dataset.take(take_n_batch)):\n",
    "    print('batch', i)\n",
    "    for arr in batch:\n",
    "        print(arr.numpy())\n",
    "        \n",
    "print('\\nBatched data, keep partial, repeat:')            \n",
    "batched_dataset = dataset.batch(batch_size, drop_remainder=False)\n",
    "batched_dataset = batched_dataset.repeat()\n",
    "\n",
    "for i, batch in enumerate(batched_dataset.take(take_n_batch)):\n",
    "    print('batch', i)\n",
    "    for arr in batch:\n",
    "        print(arr.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "[[8 9]\n",
      " [2 3]]\n",
      "[-5 -2]\n",
      "batch 1\n",
      "[[0 1]\n",
      " [6 7]]\n",
      "[-1 -4]\n",
      "batch 2\n",
      "[[4 5]]\n",
      "[-3]\n",
      "batch 3\n",
      "[[0 1]\n",
      " [4 5]]\n",
      "[-1 -3]\n",
      "batch 4\n",
      "[[6 7]\n",
      " [8 9]]\n",
      "[-4 -5]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle\n",
    "# shuffle, batch, repeat order should be kept\n",
    "shuffled = dataset.shuffle(buffer_size=100)\n",
    "shuffled = shuffled.batch(batch_size)\n",
    "shuffled = shuffled.repeat()\n",
    "for i, batch in enumerate(shuffled.take(take_n_batch)):\n",
    "    print('batch', i)\n",
    "    for arr in batch:\n",
    "        print(arr.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeseries forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[10 11 12 13 14 15 16 17 18 19]\n",
      "[20 21 22 23 24 25 26 27 28 29]\n",
      "[30 31 32 33 34 35 36 37 38 39]\n",
      "[40 41 42 43 44 45 46 47 48 49]\n"
     ]
    }
   ],
   "source": [
    "# Simple rolling window\n",
    "timeseries = tf.data.Dataset.range(100000)\n",
    "\n",
    "batches = timeseries.batch(10, drop_remainder=True)\n",
    "\n",
    "for batch in batches.take(5):\n",
    "    print(batch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]  =>  [5 6 7 8 9]\n",
      "[10 11 12 13 14]  =>  [15 16 17 18 19]\n",
      "[20 21 22 23 24]  =>  [25 26 27 28 29]\n"
     ]
    }
   ],
   "source": [
    "# Rolling window, window = feature data + data to be predicted\n",
    "def label_next_5_steps(batch):\n",
    "    return (batch[:-5],   # Take the first 5 steps\n",
    "            batch[-5:])   # take the remainder\n",
    "\n",
    "predict_5_steps = batches.map(label_next_5_steps)\n",
    "\n",
    "for features, label in predict_5_steps.take(3):\n",
    "    print(features.numpy(), \" => \", label.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]  =>  [3 4]\n",
      "[3 4 5]  =>  [6 7]\n",
      "[6 7 8]  =>  [ 9 10]\n"
     ]
    }
   ],
   "source": [
    "# Overlapping rolling window, window = feature data + data to be predicted\n",
    "feature_length = 3\n",
    "label_length = 2\n",
    "\n",
    "features = timeseries.batch(feature_length, drop_remainder=True)\n",
    "labels = timeseries.batch(feature_length).skip(1).map(lambda labels: labels[:label_length])\n",
    "\n",
    "predict_5_steps = tf.data.Dataset.zip((features, labels))\n",
    "\n",
    "for features, label in predict_5_steps.take(3):\n",
    "    print(features.numpy(), \" => \", label.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
